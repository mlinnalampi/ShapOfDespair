Time to train VGG!
[1,   100] loss: 1.168
[1,   200] loss: 0.304
[1,   300] loss: 0.186
[1,   400] loss: 0.166
[1,   500] loss: 0.147
[1,   600] loss: 0.111
[1,   700] loss: 0.123
[1,   800] loss: 0.096
[1,   900] loss: 0.097
[1,  1000] loss: 0.092
[1,  1100] loss: 0.096
[1,  1200] loss: 0.096
[1,  1300] loss: 0.064
[1,  1400] loss: 0.074
[1,  1500] loss: 0.071
[1,  1600] loss: 0.071
[1,  1700] loss: 0.069
[1,  1800] loss: 0.087
Correct: 9698 out of 10000
[2,   100] loss: 0.382
[2,   200] loss: 0.111
[2,   300] loss: 0.068
[2,   400] loss: 0.054
[2,   500] loss: 0.062
[2,   600] loss: 0.058
[2,   700] loss: 0.056
[2,   800] loss: 0.073
[2,   900] loss: 0.073
[2,  1000] loss: 0.043
[2,  1100] loss: 0.049
[2,  1200] loss: 0.059
[2,  1300] loss: 0.056
[2,  1400] loss: 0.079
[2,  1500] loss: 0.074
[2,  1600] loss: 0.062
[2,  1700] loss: 0.058
[2,  1800] loss: 0.065
Correct: 9816 out of 10000
[3,   100] loss: 0.041
[3,   200] loss: 0.065
[3,   300] loss: 0.044
[3,   400] loss: 0.056
[3,   500] loss: 0.060
[3,   600] loss: 0.068
[3,   700] loss: 0.064
[3,   800] loss: 0.054
[3,   900] loss: 0.045
[3,  1000] loss: 0.057
[3,  1100] loss: 0.074
[3,  1200] loss: 0.055
[3,  1300] loss: 0.052
[3,  1400] loss: 0.062
[3,  1500] loss: 0.055
[3,  1600] loss: 0.036
[3,  1700] loss: 0.042
[3,  1800] loss: 0.050
Correct: 9854 out of 10000
[4,   100] loss: 0.051
[4,   200] loss: 0.041
[4,   300] loss: 0.038
[4,   400] loss: 0.046
[4,   500] loss: 0.049
[4,   600] loss: 0.052
[4,   700] loss: 0.028
[4,   800] loss: 0.048
[4,   900] loss: 0.047
[4,  1000] loss: 0.042
[4,  1100] loss: 0.052
[4,  1200] loss: 0.049
[4,  1300] loss: 0.070
[4,  1400] loss: 0.053
[4,  1500] loss: 0.051
[4,  1600] loss: 0.034
[4,  1700] loss: 0.051
[4,  1800] loss: 0.049
Correct: 9908 out of 10000
[5,   100] loss: 0.034
[5,   200] loss: 0.033
[5,   300] loss: 0.041
[5,   400] loss: 0.039
[5,   500] loss: 0.039
[5,   600] loss: 0.051
[5,   700] loss: 0.035
[5,   800] loss: 0.044
[5,   900] loss: 0.026
[5,  1000] loss: 0.048
[5,  1100] loss: 0.047
[5,  1200] loss: 0.042
[5,  1300] loss: 0.033
[5,  1400] loss: 0.033
[5,  1500] loss: 0.038
[5,  1600] loss: 0.062
[5,  1700] loss: 0.045
[5,  1800] loss: 0.034
Correct: 9883 out of 10000
[6,   100] loss: 0.042
[6,   200] loss: 0.025
[6,   300] loss: 0.042
[6,   400] loss: 0.029
[6,   500] loss: 0.042
[6,   600] loss: 0.029
[6,   700] loss: 0.046
[6,   800] loss: 0.044
[6,   900] loss: 0.040
[6,  1000] loss: 0.043
[6,  1100] loss: 0.035
[6,  1200] loss: 0.029
[6,  1300] loss: 0.045
[6,  1400] loss: 0.037
[6,  1500] loss: 0.038
[6,  1600] loss: 0.042
[6,  1700] loss: 0.038
[6,  1800] loss: 0.039
Correct: 9889 out of 10000
[7,   100] loss: 0.026
[7,   200] loss: 0.034
[7,   300] loss: 0.030
[7,   400] loss: 0.040
[7,   500] loss: 0.040
[7,   600] loss: 0.042
[7,   700] loss: 0.035
[7,   800] loss: 0.041
[7,   900] loss: 0.028
[7,  1000] loss: 0.026
[7,  1100] loss: 0.023
[7,  1200] loss: 0.039
[7,  1300] loss: 0.037
[7,  1400] loss: 0.037
[7,  1500] loss: 0.036
[7,  1600] loss: 0.028
[7,  1700] loss: 0.043
[7,  1800] loss: 0.026
Correct: 9851 out of 10000
[8,   100] loss: 0.041
[8,   200] loss: 0.028
[8,   300] loss: 0.030
[8,   400] loss: 0.038
[8,   500] loss: 0.036
[8,   600] loss: 0.046
[8,   700] loss: 0.032
[8,   800] loss: 0.026
[8,   900] loss: 0.035
[8,  1000] loss: 0.027
[8,  1100] loss: 0.019
[8,  1200] loss: 0.029
[8,  1300] loss: 0.028
[8,  1400] loss: 0.027
[8,  1500] loss: 0.040
[8,  1600] loss: 0.036
[8,  1700] loss: 0.036
[8,  1800] loss: 0.030
Correct: 9931 out of 10000
Finished Training
Correct: 9931 out of 10000
It took 474.56329107284546 to compute VGG
Time for SHAP!
[1,    50] loss: 2.439
[1,   100] loss: 0.081
[1,   150] loss: 0.063
[1,   200] loss: 0.053
[1,   250] loss: 0.071
[1,   300] loss: 0.041
[1,   350] loss: 0.021
[1,   400] loss: 0.035
[1,   450] loss: 0.063
[1,   500] loss: 0.018
[1,   550] loss: 0.050
[1,   600] loss: 0.023
[1,   650] loss: 0.035
[1,   700] loss: 0.077
[1,   750] loss: 0.033
[1,   800] loss: 0.012
[1,   850] loss: 0.011
[1,   900] loss: 0.036
[1,   950] loss: 0.040
[1,  1000] loss: 0.033
[1,  1050] loss: 0.037
[1,  1100] loss: 0.047
[1,  1150] loss: 0.019
[1,  1200] loss: 0.047
[1,  1250] loss: 0.103
[1,  1300] loss: 5.125
[1,  1350] loss: 5.624
[1,  1400] loss: 16.899
[1,  1450] loss: 9.460
[1,  1500] loss: 0.196
[1,  1550] loss: 9.948
[1,  1600] loss: 2.271
[1,  1650] loss: 4.472
[1,  1700] loss: 2.644
[1,  1750] loss: 2.438
[1,  1800] loss: 1.421
[1,  1850] loss: 0.801
[2,    50] loss: 0.436
[2,   100] loss: 0.213
[2,   150] loss: 0.241
[2,   200] loss: 0.489
[2,   250] loss: 0.138
[2,   300] loss: 0.086
[2,   350] loss: 0.156
[2,   400] loss: 0.247
[2,   450] loss: 0.380
[2,   500] loss: 0.171
[2,   550] loss: 0.309
[2,   600] loss: 0.061
[2,   650] loss: 0.251
[2,   700] loss: 0.377
[2,   750] loss: 0.086
[2,   800] loss: 0.256
[2,   850] loss: 0.279
[2,   900] loss: 0.143
[2,   950] loss: 0.115
[2,  1000] loss: 0.064
[2,  1050] loss: 1.126
[2,  1100] loss: 0.283
[2,  1150] loss: 0.280
[2,  1200] loss: 0.725
[2,  1250] loss: 0.452
[2,  1300] loss: 0.135
[2,  1350] loss: 0.083
[2,  1400] loss: 0.247
[2,  1450] loss: 0.228
[2,  1500] loss: 0.084
[2,  1550] loss: 0.102
[2,  1600] loss: 0.044
[2,  1650] loss: 0.297
[2,  1700] loss: 0.104
[2,  1750] loss: 0.085
[2,  1800] loss: 0.450
[2,  1850] loss: 0.159
Finished Training
It took 89868.2623770237 to train Post Shap Classifier
Grand total in time was 90342.8924870491
